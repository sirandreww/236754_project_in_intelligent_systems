{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df56602b-a665-458b-a581-dd1faa97b5e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Long Short-Term Memory (LSTM)\n",
    "\n",
    "## What is LSTM? \n",
    "LSTM stands for long short-term memory networks, used in the field of Deep Learning. It is a variety of recurrent neural networks (RNNs) that are capable of learning long-term dependencies, especially in sequence prediction problems. \n",
    "LSTM has feedback connections, i.e., it is capable of processing the entire sequence of data, apart from single data points such as images.\n",
    "This finds application in speech recognition, machine translation, etc. LSTM is a special kind of RNN, which shows outstanding performance on a large variety of problems.\n",
    "\n",
    "worth watching: https://www.youtube.com/watch?v=b61DPVFX03I&t=329s\n",
    "\n",
    "## Our LSTM Implementation:\n",
    "\n",
    "Our implementation of the LSTM is available in `./src/lstm.py`. The implementation includes the model as well as all that's needed for the test besnch to be able to use the model. let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a692a2a-ce27-4151-9094-d25ecee04bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import src.lstm_pytorch as lstm\n",
    "import src.test_bench as bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ea1ec-ecf4-48d8-a0e4-36993f0090af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST BENCH] Powering on test bench\n",
      "[TEST BENCH] testing metric='node_mem', app='moc/smaug'.\n",
      "[TEST BENCH] Fetching data for metric='node_mem', app='moc/smaug'.\n",
      "[TEST BENCH] Subsampling data from 1 sample per 1 minute to 1 sample per 5 minutes.\n",
      "[TEST BENCH] Throwing out data that is less than 500 minutes long.\n",
      "[TEST BENCH] Scaling data.\n",
      "[TEST BENCH] Splitting data into train and test\n",
      "[TEST BENCH] Amount of train data is 76\n",
      "[TEST BENCH] Amount of test data is 18\n",
      "[TEST BENCH] Making an instance of the class we want to test\n",
      "[PytorchTester] criterion = MSELoss()\n",
      "[PytorchLSTMTester] model = LSTMPredictor(\n",
      "  (model): Sequential(\n",
      "    (0): LSTM(1, 200, num_layers=2, batch_first=True, dropout=0.1)\n",
      "    (1): ExtractTensorAfterLSTM()\n",
      "    (2): Linear(in_features=200, out_features=32, bias=True)\n",
      "    (3): Linear(in_features=32, out_features=248, bias=True)\n",
      "  )\n",
      ")\n",
      "[PytorchLSTMTester] learning_rate = 0.001\n",
      "[PytorchLSTMTester] optimizer = Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "[PytorchLSTMTester] batch_size = 64\n",
      "[PytorchLSTMTester] padding = -99999\n",
      "[PytorchLSTMTester] num_epochs = 8\n",
      "[TEST BENCH] Starting training loop\n",
      "[PytorchTester] Length of list_of_samples =  4180\n",
      "[PytorchTester] Epoch 1 / 8. Last epoch time was 0\n"
     ]
    }
   ],
   "source": [
    "tb = bench.TestBench(\n",
    "    class_to_test=lstm.PytorchLSTMTester,\n",
    "    tests_to_perform=[\n",
    "        {\"metric\": \"node_mem\", \"app\": \"moc/smaug\", \"test percentage\": 0.2, \"sub sample rate\": 5, \"data length limit\": 100},\n",
    "        {\"metric\": \"node_mem\", \"app\": \"emea/balrog\", \"test percentage\": 0.2, \"sub sample rate\": 5, \"data length limit\": 100},\n",
    "    ],\n",
    "    path_to_data=\"./data/\"\n",
    ")\n",
    "tb.run_training_and_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f33c6-413b-474c-83ac-d075a1349106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521f707-06ab-443e-b9a2-808ba7e3b66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
