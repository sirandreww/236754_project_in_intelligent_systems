{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df56602b-a665-458b-a581-dd1faa97b5e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Long Short-Term Memory (LSTM)\n",
    "\n",
    "## What is LSTM? \n",
    "LSTM stands for long short-term memory networks, used in the field of Deep Learning. It is a variety of recurrent neural networks (RNNs) that are capable of learning long-term dependencies, especially in sequence prediction problems. \n",
    "LSTM has feedback connections, i.e., it is capable of processing the entire sequence of data, apart from single data points such as images.\n",
    "This finds application in speech recognition, machine translation, etc. LSTM is a special kind of RNN, which shows outstanding performance on a large variety of problems.\n",
    "\n",
    "worth watching: https://www.youtube.com/watch?v=b61DPVFX03I&t=329s\n",
    "\n",
    "## Our LSTM Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f64f335-4d1e-402c-be84-209083e4027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17ea1ec-ecf4-48d8-a0e4-36993f0090af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, n_hidden=51):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lstm1 = nn.LSTMCell(1, self.n_hidden)\n",
    "        self.lstm2 = nn.LSTMCell(self.n_hidden, self.n_hidden)\n",
    "        self.linear = nn.Linear(self.n_hidden, 1)\n",
    "\n",
    "    def forward(self, x, future=0):\n",
    "        outputs = []\n",
    "        n_samples = x.size(0)\n",
    "        h_t = torch.zeros(n_samples, self.n_hidden, dtype=torch.double)\n",
    "        c_t = torch.zeros(n_samples, self.n_hidden, dtype=torch.double)\n",
    "        h_t2 = torch.zeros(n_samples, self.n_hidden, dtype=torch.double)\n",
    "        c_t2 = torch.zeros(n_samples, self.n_hidden, dtype=torch.double)\n",
    "\n",
    "        for input_t in x.split(1, dim=1):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        for i in range(future):# if we should predict the future\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f33c6-413b-474c-83ac-d075a1349106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
