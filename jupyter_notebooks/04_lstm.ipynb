{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df56602b-a665-458b-a581-dd1faa97b5e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Long Short-Term Memory (LSTM)\n",
    "\n",
    "## What is LSTM? \n",
    "LSTM stands for long short-term memory networks, used in the field of Deep Learning. It is a variety of recurrent neural networks (RNNs) that are capable of learning long-term dependencies, especially in sequence prediction problems. \n",
    "LSTM has feedback connections, i.e., it is capable of processing the entire sequence of data, apart from single data points such as images.\n",
    "This finds application in speech recognition, machine translation, etc. LSTM is a special kind of RNN, which shows outstanding performance on a large variety of problems.\n",
    "\n",
    "worth watching: https://www.youtube.com/watch?v=b61DPVFX03I&t=329s\n",
    "\n",
    "## Our LSTM Implementation:\n",
    "\n",
    "Our implementation of the LSTM is available in `./src/lstm.py`. The implementation includes the model as well as all that's needed for the test besnch to be able to use the model. let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a692a2a-ce27-4151-9094-d25ecee04bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.lstm as lstm\n",
    "import src.test_bench as bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ea1ec-ecf4-48d8-a0e4-36993f0090af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST BENCH] Powering on test bench\n",
      "[TEST BENCH] testing metric='node_mem', app='moc/smaug'.\n",
      "[TEST BENCH] Fetching data for metric='node_mem', app='moc/smaug'.\n",
      "[TEST BENCH] Subsampling data from 1 sample per 1 minute to 1 sample per 5 minutes.\n",
      "[TEST BENCH] Throwing out data that is less than 500 minutes long.\n",
      "[TEST BENCH] Scaling data.\n",
      "[TEST BENCH] Splitting data into train and test\n",
      "[TEST BENCH] Amount of train data is 76\n",
      "[TEST BENCH] Amount of test data is 18\n",
      "[TEST BENCH] Making an instance of the class we want to test\n",
      "[PytorchTester] criterion = MSELoss()\n",
      "[LSTMTester] model = LSTMPredictor(\n",
      "  (model): Sequential(\n",
      "    (0): LSTM(1, 200, num_layers=2, batch_first=True, dropout=0.1)\n",
      "    (1): ExtractTensorAfterLSTM()\n",
      "    (2): Linear(in_features=200, out_features=32, bias=True)\n",
      "    (3): Linear(in_features=32, out_features=248, bias=True)\n",
      "  )\n",
      ")\n",
      "[LSTMTester] learning_rate = 0.001\n",
      "[LSTMTester] optimizer = Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "[LSTMTester] batch_size = 64\n",
      "[LSTMTester] padding = -99999\n",
      "[LSTMTester] num_epochs = 20\n",
      "[TEST BENCH] Starting training loop\n",
      "[PytorchTester] Length of list_of_samples =  4180\n",
      "[PytorchTester] Epoch 1 / 20. Last epoch time was 0\n",
      "[PytorchTester] loss of batch 1 / 66: 0.6255396008491516\n",
      "[PytorchTester] loss of batch 2 / 66: 1.2257510423660278\n",
      "[PytorchTester] loss of batch 3 / 66: 1.074981689453125\n",
      "[PytorchTester] loss of batch 4 / 66: 0.8205309510231018\n",
      "[PytorchTester] loss of batch 5 / 66: 1.8180465698242188\n",
      "[PytorchTester] loss of batch 6 / 66: 1.428536295890808\n",
      "[PytorchTester] loss of batch 7 / 66: 0.7925862669944763\n",
      "[PytorchTester] loss of batch 8 / 66: 1.10494065284729\n",
      "[PytorchTester] loss of batch 9 / 66: 0.6910372972488403\n",
      "[PytorchTester] loss of batch 10 / 66: 1.2913485765457153\n",
      "[PytorchTester] loss of batch 11 / 66: 0.5274733901023865\n",
      "[PytorchTester] loss of batch 12 / 66: 1.5986162424087524\n",
      "[PytorchTester] loss of batch 13 / 66: 1.0602164268493652\n",
      "[PytorchTester] loss of batch 14 / 66: 0.47415924072265625\n",
      "[PytorchTester] loss of batch 15 / 66: 1.9808425903320312\n",
      "[PytorchTester] loss of batch 16 / 66: 0.8984131813049316\n",
      "[PytorchTester] loss of batch 17 / 66: 0.9224731922149658\n",
      "[PytorchTester] loss of batch 18 / 66: 1.308954119682312\n",
      "[PytorchTester] loss of batch 19 / 66: 0.39029207825660706\n",
      "[PytorchTester] loss of batch 20 / 66: 0.9389175176620483\n",
      "[PytorchTester] loss of batch 21 / 66: 0.3196672201156616\n",
      "[PytorchTester] loss of batch 22 / 66: 0.548700213432312\n",
      "[PytorchTester] loss of batch 23 / 66: 0.5000688433647156\n",
      "[PytorchTester] loss of batch 24 / 66: 0.4403705298900604\n",
      "[PytorchTester] loss of batch 25 / 66: 0.7592318058013916\n",
      "[PytorchTester] loss of batch 26 / 66: 0.905369222164154\n",
      "[PytorchTester] loss of batch 27 / 66: 0.6956584453582764\n",
      "[PytorchTester] loss of batch 28 / 66: 0.6694560647010803\n",
      "[PytorchTester] loss of batch 29 / 66: 0.3169178068637848\n",
      "[PytorchTester] loss of batch 30 / 66: 0.8777770400047302\n",
      "[PytorchTester] loss of batch 31 / 66: 0.4085058271884918\n",
      "[PytorchTester] loss of batch 32 / 66: 1.4266544580459595\n",
      "[PytorchTester] loss of batch 33 / 66: 0.4776148498058319\n",
      "[PytorchTester] loss of batch 34 / 66: 0.656660258769989\n",
      "[PytorchTester] loss of batch 35 / 66: 0.3937152028083801\n",
      "[PytorchTester] loss of batch 36 / 66: 0.6743104457855225\n",
      "[PytorchTester] loss of batch 37 / 66: 0.43073466420173645\n",
      "[PytorchTester] loss of batch 38 / 66: 0.6180161237716675\n",
      "[PytorchTester] loss of batch 39 / 66: 0.46153122186660767\n",
      "[PytorchTester] loss of batch 40 / 66: 0.34481632709503174\n",
      "[PytorchTester] loss of batch 41 / 66: 1.2175408601760864\n",
      "[PytorchTester] loss of batch 42 / 66: 0.289134681224823\n",
      "[PytorchTester] loss of batch 43 / 66: 0.48605284094810486\n",
      "[PytorchTester] loss of batch 44 / 66: 0.171445831656456\n",
      "[PytorchTester] loss of batch 45 / 66: 0.20130512118339539\n",
      "[PytorchTester] loss of batch 46 / 66: 0.7977573275566101\n"
     ]
    }
   ],
   "source": [
    "tb = bench.TestBench(\n",
    "    class_to_test=lstm.LSTMTester,\n",
    "    tests_to_perform=[\n",
    "        {\"metric\": \"node_mem\", \"app\": \"moc/smaug\", \"test percentage\": 0.2, \"sub sample rate\": 5, \"data length limit\": 100},\n",
    "        {\"metric\": \"node_mem\", \"app\": \"emea/balrog\", \"test percentage\": 0.2, \"sub sample rate\": 5, \"data length limit\": 100},\n",
    "    ],\n",
    "    path_to_data=\"./data/\"\n",
    ")\n",
    "tb.run_training_and_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f33c6-413b-474c-83ac-d075a1349106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521f707-06ab-443e-b9a2-808ba7e3b66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
