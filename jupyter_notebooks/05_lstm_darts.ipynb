{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df56602b-a665-458b-a581-dd1faa97b5e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Long Short-Term Memory (LSTM) Using Darts\n",
    "\n",
    "## What is LSTM? \n",
    "\n",
    "Darts is a python time series forcasting library, we wanted to see what it can do with its implementation of lstm. How much does it differ from ours? Is it better or worse?  what about trainning time?\n",
    "\n",
    "## Darts LSTM Implementation:\n",
    "\n",
    "# TODO: change this\n",
    "Our implementation of the LSTM is available in `./src/lstm.py`. The implementation includes the model as well as all that's needed for the test besnch to be able to use the model. let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba5c980-80f7-4fad-b4b2-1a1b85178ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.lstm_darts\n",
    "import src.test_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b937e4f-bf66-4243-aa23-d3f649305cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST BENCH] Powering on test bench\n",
      "[TEST BENCH] testing metric='node_mem', app='moc/smaug'.\n",
      "[TEST BENCH] Fetching data for metric='node_mem', app='moc/smaug'.\n",
      "[TEST BENCH] Subsampling data from 1 sample per 1 minute to 1 sample per 5 minutes.\n",
      "[TEST BENCH] Throwing out data that is less than 500 minutes long.\n",
      "[TEST BENCH] Scaling data.\n",
      "[TEST BENCH] Splitting data into train and test\n",
      "[TEST BENCH] Amount of train data is 76\n",
      "[TEST BENCH] Amount of test data is 18\n",
      "[TEST BENCH] Making an instance of the class we want to test\n",
      "[TEST BENCH] Starting training loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 23:24:44,372\tWARNING function_runner.py:603 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2022-07-14 23:24:44,627\tERROR syncer.py:147 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:24:44 (running for 00:00:00.22)\n",
      "Memory usage on this node: 5.3/7.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: None\n",
      "Resources requested: 1.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+\n",
      "| Trial name              | status   | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |\n",
      "|-------------------------+----------+-----------------+--------------+--------------+--------------+-------------|\n",
      "| train_model_ff7c7_00000 | RUNNING  | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 |\n",
      "| train_model_ff7c7_00001 | PENDING  |                 |           64 |            3 |           64 | 0.119281    |\n",
      "| train_model_ff7c7_00002 | PENDING  |                 |           16 |            3 |           32 | 0.150703    |\n",
      "| train_model_ff7c7_00003 | PENDING  |                 |           32 |            5 |           32 | 0.178488    |\n",
      "| train_model_ff7c7_00004 | PENDING  |                 |           32 |            2 |           64 | 0.152062    |\n",
      "| train_model_ff7c7_00005 | PENDING  |                 |          128 |            5 |           64 | 0.108562    |\n",
      "| train_model_ff7c7_00006 | PENDING  |                 |           32 |            2 |          128 | 0.105872    |\n",
      "| train_model_ff7c7_00007 | PENDING  |                 |           16 |            3 |           64 | 0.164264    |\n",
      "| train_model_ff7c7_00008 | PENDING  |                 |          128 |            4 |           32 | 0.196078    |\n",
      "| train_model_ff7c7_00009 | PENDING  |                 |           16 |            3 |           64 | 0.127511    |\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:24:49 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:24:49 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:24:49 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:24:49 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:24:49 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:24:49 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:24:50 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 3 | stacks        | ModuleList       | 39.7 M\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 39.7 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 39.7 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 317.279   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:24:54 (running for 00:00:10.06)\n",
      "Memory usage on this node: 6.9/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: None\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 PENDING, 6 RUNNING)\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+\n",
      "| Trial name              | status   | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |\n",
      "|-------------------------+----------+-----------------+--------------+--------------+--------------+-------------|\n",
      "| train_model_ff7c7_00000 | RUNNING  | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 |\n",
      "| train_model_ff7c7_00001 | RUNNING  | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |\n",
      "| train_model_ff7c7_00002 | RUNNING  | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |\n",
      "| train_model_ff7c7_00003 | RUNNING  | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |\n",
      "| train_model_ff7c7_00004 | RUNNING  | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |\n",
      "| train_model_ff7c7_00005 | RUNNING  | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |\n",
      "| train_model_ff7c7_00006 | PENDING  |                 |           32 |            2 |          128 | 0.105872    |\n",
      "| train_model_ff7c7_00007 | PENDING  |                 |           16 |            3 |           64 | 0.164264    |\n",
      "| train_model_ff7c7_00008 | PENDING  |                 |          128 |            4 |           32 | 0.196078    |\n",
      "| train_model_ff7c7_00009 | PENDING  |                 |           16 |            3 |           64 | 0.127511    |\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:00 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:25:00 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:00 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:25:00 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:00 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:00 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:00 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00000:\n",
      "  MAPE: 1102.5564477061953\n",
      "  date: 2022-07-14_23-25-01\n",
      "  done: false\n",
      "  experiment_id: cef0e99354ea440aa2f5ed43bac9c53f\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 13852\n",
      "  time_since_restore: 11.907882452011108\n",
      "  time_this_iter_s: 11.907882452011108\n",
      "  time_total_s: 11.907882452011108\n",
      "  timestamp: 1657830301\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00000\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 3 | stacks        | ModuleList       | 19.8 M\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 19.8 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 19.8 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 158.640   Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:00 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:00 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:25:01,193\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:25:01 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:25:01 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:25:01 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:25:01 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:25:01 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:01 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 3 | stacks        | ModuleList       | 26.4 M\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 26.4 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 26.4 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 211.519   Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:25:02 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 3 | stacks        | ModuleList       | 39.7 M\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 39.7 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 39.7 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 317.279   Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:02 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 3 | stacks        | ModuleList       | 33.0 M\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 33.0 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 33.0 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 264.399   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:25:02 (running for 00:00:18.23)\n",
      "Memory usage on this node: 7.4/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: None\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00000 with MAPE=1102.5564477061953 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 64, 'dropout': 0.0008876227471853682}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 PENDING, 6 RUNNING)\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------+\n",
      "| Trial name              | status   | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |    MAPE |   training_iteration |\n",
      "|-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING  | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56 |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING  | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |         |                      |\n",
      "| train_model_ff7c7_00002 | RUNNING  | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |         |                      |\n",
      "| train_model_ff7c7_00003 | RUNNING  | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |         |                      |\n",
      "| train_model_ff7c7_00004 | RUNNING  | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |         |                      |\n",
      "| train_model_ff7c7_00005 | RUNNING  | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |         |                      |\n",
      "| train_model_ff7c7_00006 | PENDING  |                 |           32 |            2 |          128 | 0.105872    |         |                      |\n",
      "| train_model_ff7c7_00007 | PENDING  |                 |           16 |            3 |           64 | 0.164264    |         |                      |\n",
      "| train_model_ff7c7_00008 | PENDING  |                 |          128 |            4 |           32 | 0.196078    |         |                      |\n",
      "| train_model_ff7c7_00009 | PENDING  |                 |           16 |            3 |           64 | 0.127511    |         |                      |\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:25:02 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:25:02 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:25:02 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:25:02 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:25:02 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:25:07 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 3 | stacks        | ModuleList       | 66.1 M\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 66.1 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 66.1 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 528.799   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:25:08 (running for 00:00:23.62)\n",
      "Memory usage on this node: 7.4/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: None\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00000 with MAPE=1102.5564477061953 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 64, 'dropout': 0.0008876227471853682}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 PENDING, 6 RUNNING)\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------+\n",
      "| Trial name              | status   | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |    MAPE |   training_iteration |\n",
      "|-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING  | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56 |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING  | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |         |                      |\n",
      "| train_model_ff7c7_00002 | RUNNING  | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |         |                      |\n",
      "| train_model_ff7c7_00003 | RUNNING  | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |         |                      |\n",
      "| train_model_ff7c7_00004 | RUNNING  | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |         |                      |\n",
      "| train_model_ff7c7_00005 | RUNNING  | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |         |                      |\n",
      "| train_model_ff7c7_00006 | PENDING  |                 |           32 |            2 |          128 | 0.105872    |         |                      |\n",
      "| train_model_ff7c7_00007 | PENDING  |                 |           16 |            3 |           64 | 0.164264    |         |                      |\n",
      "| train_model_ff7c7_00008 | PENDING  |                 |          128 |            4 |           32 | 0.196078    |         |                      |\n",
      "| train_model_ff7c7_00009 | PENDING  |                 |           16 |            3 |           64 | 0.127511    |         |                      |\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:25:14 (running for 00:00:29.83)\n",
      "Memory usage on this node: 7.4/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: None\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00000 with MAPE=1102.5564477061953 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 64, 'dropout': 0.0008876227471853682}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 PENDING, 6 RUNNING)\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------+\n",
      "| Trial name              | status   | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |    MAPE |   training_iteration |\n",
      "|-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING  | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56 |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING  | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |         |                      |\n",
      "| train_model_ff7c7_00002 | RUNNING  | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |         |                      |\n",
      "| train_model_ff7c7_00003 | RUNNING  | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |         |                      |\n",
      "| train_model_ff7c7_00004 | RUNNING  | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |         |                      |\n",
      "| train_model_ff7c7_00005 | RUNNING  | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |         |                      |\n",
      "| train_model_ff7c7_00006 | PENDING  |                 |           32 |            2 |          128 | 0.105872    |         |                      |\n",
      "| train_model_ff7c7_00007 | PENDING  |                 |           16 |            3 |           64 | 0.164264    |         |                      |\n",
      "| train_model_ff7c7_00008 | PENDING  |                 |          128 |            4 |           32 | 0.196078    |         |                      |\n",
      "| train_model_ff7c7_00009 | PENDING  |                 |           16 |            3 |           64 | 0.127511    |         |                      |\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:28,242\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:30,495\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:32,895\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:25:33 (running for 00:00:49.21)\n",
      "Memory usage on this node: 6.5/7.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: None\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00000 with MAPE=1102.5564477061953 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 64, 'dropout': 0.0008876227471853682}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 PENDING, 6 RUNNING)\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------+\n",
      "| Trial name              | status   | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |    MAPE |   training_iteration |\n",
      "|-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING  | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56 |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING  | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |         |                      |\n",
      "| train_model_ff7c7_00002 | RUNNING  | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |         |                      |\n",
      "| train_model_ff7c7_00003 | RUNNING  | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |         |                      |\n",
      "| train_model_ff7c7_00004 | RUNNING  | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |         |                      |\n",
      "| train_model_ff7c7_00005 | RUNNING  | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |         |                      |\n",
      "| train_model_ff7c7_00006 | PENDING  |                 |           32 |            2 |          128 | 0.105872    |         |                      |\n",
      "| train_model_ff7c7_00007 | PENDING  |                 |           16 |            3 |           64 | 0.164264    |         |                      |\n",
      "| train_model_ff7c7_00008 | PENDING  |                 |          128 |            4 |           32 | 0.196078    |         |                      |\n",
      "| train_model_ff7c7_00009 | PENDING  |                 |           16 |            3 |           64 | 0.127511    |         |                      |\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+---------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00003:\n",
      "  MAPE: 2.725974668623566\n",
      "  date: 2022-07-14_23-25-33\n",
      "  done: false\n",
      "  experiment_id: 06a9d814057246ae88a3915674f13ce1\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 7176\n",
      "  time_since_restore: 33.25494718551636\n",
      "  time_this_iter_s: 33.25494718551636\n",
      "  time_total_s: 33.25494718551636\n",
      "  timestamp: 1657830333\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00003\n",
      "  warmup_time: 0.022005319595336914\n",
      "  \n",
      "Result for train_model_ff7c7_00002:\n",
      "  MAPE: 2.137129182448991\n",
      "  date: 2022-07-14_23-25-30\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 30.666300535202026\n",
      "  time_this_iter_s: 30.666300535202026\n",
      "  time_total_s: 30.666300535202026\n",
      "  timestamp: 1657830330\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00002\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "Result for train_model_ff7c7_00004:\n",
      "  MAPE: 7.918487163938397\n",
      "  date: 2022-07-14_23-25-28\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 28.708330392837524\n",
      "  time_this_iter_s: 28.708330392837524\n",
      "  time_total_s: 28.708330392837524\n",
      "  timestamp: 1657830328\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00004\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:25:39 (running for 00:00:55.28)\n",
      "Memory usage on this node: 7.1/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: None\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=2.137129182448991 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 PENDING, 6 RUNNING)\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+------------+----------------------+\n",
      "| Trial name              | status   | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |       MAPE |   training_iteration |\n",
      "|-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING  | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56    |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING  | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |            |                      |\n",
      "| train_model_ff7c7_00002 | RUNNING  | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    2.13713 |                    1 |\n",
      "| train_model_ff7c7_00003 | RUNNING  | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    2.72597 |                    1 |\n",
      "| train_model_ff7c7_00004 | RUNNING  | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    7.91849 |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING  | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |            |                      |\n",
      "| train_model_ff7c7_00006 | PENDING  |                 |           32 |            2 |          128 | 0.105872    |            |                      |\n",
      "| train_model_ff7c7_00007 | PENDING  |                 |           16 |            3 |           64 | 0.164264    |            |                      |\n",
      "| train_model_ff7c7_00008 | PENDING  |                 |          128 |            4 |           32 | 0.196078    |            |                      |\n",
      "| train_model_ff7c7_00009 | PENDING  |                 |           16 |            3 |           64 | 0.127511    |            |                      |\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00004:\n",
      "  MAPE: 6.941310260664238\n",
      "  date: 2022-07-14_23-25-41\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 41.646010875701904\n",
      "  time_this_iter_s: 12.93768048286438\n",
      "  time_total_s: 41.646010875701904\n",
      "  timestamp: 1657830341\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: ff7c7_00004\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:41,688\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:42,017\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00002:\n",
      "  MAPE: 1.5230641719693259\n",
      "  date: 2022-07-14_23-25-42\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 41.975088596343994\n",
      "  time_this_iter_s: 11.308788061141968\n",
      "  time_total_s: 41.975088596343994\n",
      "  timestamp: 1657830342\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: ff7c7_00002\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "Result for train_model_ff7c7_00003:\n",
      "  MAPE: 2.170438339861102\n",
      "  date: 2022-07-14_23-25-43\n",
      "  done: false\n",
      "  experiment_id: 06a9d814057246ae88a3915674f13ce1\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 7176\n",
      "  time_since_restore: 43.18335938453674\n",
      "  time_this_iter_s: 9.928412199020386\n",
      "  time_total_s: 43.18335938453674\n",
      "  timestamp: 1657830343\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: ff7c7_00003\n",
      "  warmup_time: 0.022005319595336914\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:43,228\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:25:43,362\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00001:\n",
      "  MAPE: 6.383421346583243\n",
      "  date: 2022-07-14_23-25-43\n",
      "  done: false\n",
      "  experiment_id: 165379d311a540dc8317526e3cbddcc0\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12664\n",
      "  time_since_restore: 43.32238698005676\n",
      "  time_this_iter_s: 43.32238698005676\n",
      "  time_total_s: 43.32238698005676\n",
      "  timestamp: 1657830343\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00001\n",
      "  warmup_time: 0.03100752830505371\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 23:25:55,413\tWARNING util.py:214 -- The `callbacks.on_trial_result` operation took 11.982 s, which may be a performance bottleneck.\n",
      "2022-07-14 23:25:55,416\tWARNING util.py:214 -- The `process_trial_result` operation took 11.985 s, which may be a performance bottleneck.\n",
      "2022-07-14 23:25:55,417\tWARNING util.py:214 -- Processing trial results took 11.986 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2022-07-14 23:25:55,418\tWARNING util.py:214 -- The `process_trial_result` operation took 11.988 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:25:47,743\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:25:47,843\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:51,626\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:25:55 (running for 00:01:11.01)\n",
      "Memory usage on this node: 7.1/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: None\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=1.5230641719693259 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 PENDING, 6 RUNNING)\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+------------+----------------------+\n",
      "| Trial name              | status   | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |       MAPE |   training_iteration |\n",
      "|-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING  | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56    |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING  | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342 |                    1 |\n",
      "| train_model_ff7c7_00002 | RUNNING  | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    1.52306 |                    2 |\n",
      "| train_model_ff7c7_00003 | RUNNING  | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    2.17044 |                    2 |\n",
      "| train_model_ff7c7_00004 | RUNNING  | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    6.94131 |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING  | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |            |                      |\n",
      "| train_model_ff7c7_00006 | PENDING  |                 |           32 |            2 |          128 | 0.105872    |            |                      |\n",
      "| train_model_ff7c7_00007 | PENDING  |                 |           16 |            3 |           64 | 0.164264    |            |                      |\n",
      "| train_model_ff7c7_00008 | PENDING  |                 |          128 |            4 |           32 | 0.196078    |            |                      |\n",
      "| train_model_ff7c7_00009 | PENDING  |                 |           16 |            3 |           64 | 0.127511    |            |                      |\n",
      "+-------------------------+----------+-----------------+--------------+--------------+--------------+-------------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00002:\n",
      "  MAPE: 0.360550726959412\n",
      "  date: 2022-07-14_23-25-47\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 47.80140209197998\n",
      "  time_this_iter_s: 5.826313495635986\n",
      "  time_total_s: 47.80140209197998\n",
      "  timestamp: 1657830347\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00002\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "Result for train_model_ff7c7_00003:\n",
      "  MAPE: 1.0511476478931494\n",
      "  date: 2022-07-14_23-25-51\n",
      "  done: true\n",
      "  experiment_id: 06a9d814057246ae88a3915674f13ce1\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 7176\n",
      "  time_since_restore: 51.67110228538513\n",
      "  time_this_iter_s: 8.487742900848389\n",
      "  time_total_s: 51.67110228538513\n",
      "  timestamp: 1657830351\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00003\n",
      "  warmup_time: 0.022005319595336914\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 23:25:56,762\tWARNING util.py:214 -- The `start_trial` operation took 1.223 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00004:\n",
      "  MAPE: 1.9748837286597272\n",
      "  date: 2022-07-14_23-25-47\n",
      "  done: true\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 47.701377391815186\n",
      "  time_this_iter_s: 6.055366516113281\n",
      "  time_total_s: 47.701377391815186\n",
      "  timestamp: 1657830347\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00004\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:57 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:58 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:59 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:59 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:59 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:25:59 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00002:\n",
      "  MAPE: 0.6187790794964138\n",
      "  date: 2022-07-14_23-26-00\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 60.4654860496521\n",
      "  time_this_iter_s: 12.66408395767212\n",
      "  time_total_s: 60.4654860496521\n",
      "  timestamp: 1657830360\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: ff7c7_00002\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:00 (running for 00:01:16.13)\n",
      "Memory usage on this node: 7.4/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.6187790794964138 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (2 PENDING, 6 RUNNING, 2 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00002 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.618779 |                    4 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |             |                      |\n",
      "| train_model_ff7c7_00008 | PENDING    |                 |          128 |            4 |           32 | 0.196078    |             |                      |\n",
      "| train_model_ff7c7_00009 | PENDING    |                 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:00,506\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:00 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:26:01 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 3 | stacks        | ModuleList       | 52.9 M\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 52.9 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 52.9 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 423.039   Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:02 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:02 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:02 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:02 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:02 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:03 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 3 | stacks        | ModuleList       | 39.7 M\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 39.7 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 39.7 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 317.279   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:05 (running for 00:01:21.28)\n",
      "Memory usage on this node: 7.4/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.6187790794964138 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (2 PENDING, 6 RUNNING, 2 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00002 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.618779 |                    4 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |             |                      |\n",
      "| train_model_ff7c7_00008 | PENDING    |                 |          128 |            4 |           32 | 0.196078    |             |                      |\n",
      "| train_model_ff7c7_00009 | PENDING    |                 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:05,918\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00002:\n",
      "  MAPE: 0.16722439265646552\n",
      "  date: 2022-07-14_23-26-06\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 65.95228958129883\n",
      "  time_this_iter_s: 5.4868035316467285\n",
      "  time_total_s: 65.95228958129883\n",
      "  timestamp: 1657830366\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: ff7c7_00002\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:11 (running for 00:01:27.21)\n",
      "Memory usage on this node: 7.1/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: None | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.16722439265646552 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (2 PENDING, 6 RUNNING, 2 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00002 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.167224 |                    5 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |             |                      |\n",
      "| train_model_ff7c7_00008 | PENDING    |                 |          128 |            4 |           32 | 0.196078    |             |                      |\n",
      "| train_model_ff7c7_00009 | PENDING    |                 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00002:\n",
      "  MAPE: 0.20639391432270093\n",
      "  date: 2022-07-14_23-26-14\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 74.83326840400696\n",
      "  time_this_iter_s: 8.88097882270813\n",
      "  time_total_s: 74.83326840400696\n",
      "  timestamp: 1657830374\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: ff7c7_00002\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:14,841\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:20 (running for 00:01:35.66)\n",
      "Memory usage on this node: 6.8/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.20639391432270093 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.24756784033020454 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (2 PENDING, 6 RUNNING, 2 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00002 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.247568 |                    7 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |             |                      |\n",
      "| train_model_ff7c7_00008 | PENDING    |                 |          128 |            4 |           32 | 0.196078    |             |                      |\n",
      "| train_model_ff7c7_00009 | PENDING    |                 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:19,992\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:21,174\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 4.7214043173250975\n",
      "  date: 2022-07-14_23-26-21\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 24.045403242111206\n",
      "  time_this_iter_s: 24.045403242111206\n",
      "  time_total_s: 24.045403242111206\n",
      "  timestamp: 1657830381\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "Result for train_model_ff7c7_00002:\n",
      "  MAPE: 0.15864962606778774\n",
      "  date: 2022-07-14_23-26-25\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 85.06547713279724\n",
      "  time_this_iter_s: 5.07925271987915\n",
      "  time_total_s: 85.06547713279724\n",
      "  timestamp: 1657830385\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: ff7c7_00002\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:25 (running for 00:01:40.70)\n",
      "Memory usage on this node: 7.0/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.20639391432270093 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.15864962606778774 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (2 PENDING, 6 RUNNING, 2 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |       MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56    |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342 |                    1 |\n",
      "| train_model_ff7c7_00002 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.15865 |                    8 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |            |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |            |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    4.7214  |                    1 |\n",
      "| train_model_ff7c7_00008 | PENDING    |                 |          128 |            4 |           32 | 0.196078    |            |                      |\n",
      "| train_model_ff7c7_00009 | PENDING    |                 |           16 |            3 |           64 | 0.127511    |            |                      |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115 |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488 |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:25,106\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:29,645\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 2.5917955035649785\n",
      "  date: 2022-07-14_23-26-31\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 33.859620094299316\n",
      "  time_this_iter_s: 9.81421685218811\n",
      "  time_total_s: 33.859620094299316\n",
      "  timestamp: 1657830391\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:31 (running for 00:01:46.61)\n",
      "Memory usage on this node: 7.0/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.20639391432270093 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.16697593255320956 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (2 PENDING, 6 RUNNING, 2 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00002 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.166976 |                    9 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    2.5918   |                    2 |\n",
      "| train_model_ff7c7_00008 | PENDING    |                 |          128 |            4 |           32 | 0.196078    |             |                      |\n",
      "| train_model_ff7c7_00009 | PENDING    |                 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:31,016\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:34,351\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00002:\n",
      "  MAPE: 0.1339306734536803\n",
      "  date: 2022-07-14_23-26-34\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 94.30956411361694\n",
      "  time_this_iter_s: 4.706062316894531\n",
      "  time_total_s: 94.30956411361694\n",
      "  timestamp: 1657830394\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: ff7c7_00002\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "Result for train_model_ff7c7_00002:\n",
      "  MAPE: 0.1339306734536803\n",
      "  date: 2022-07-14_23-26-34\n",
      "  done: true\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  experiment_tag: 2_batch_size=16,dropout=0.1507,num_blocks=3,num_stacks=32\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 94.30956411361694\n",
      "  time_this_iter_s: 4.706062316894531\n",
      "  time_total_s: 94.30956411361694\n",
      "  timestamp: 1657830394\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: ff7c7_00002\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:39 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:40 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.36469503466921793\n",
      "  date: 2022-07-14_23-26-40\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 43.12739586830139\n",
      "  time_this_iter_s: 9.267775774002075\n",
      "  time_total_s: 43.12739586830139\n",
      "  timestamp: 1657830400\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:40,283\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:40 (running for 00:01:56.27)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.20639391432270093 | Iter 3.000: -0.7079213412811837\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (1 PENDING, 6 RUNNING, 3 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.364695 |                    3 |\n",
      "| train_model_ff7c7_00008 | RUNNING    | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |             |                      |\n",
      "| train_model_ff7c7_00009 | PENDING    |                 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:41 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:41 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:41 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:41 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:42 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 3 | stacks        | ModuleList       | 26.4 M\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 26.4 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 26.4 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 211.519   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:45 (running for 00:02:01.31)\n",
      "Memory usage on this node: 7.3/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.20639391432270093 | Iter 3.000: -0.7079213412811837\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (1 PENDING, 6 RUNNING, 3 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.364695 |                    3 |\n",
      "| train_model_ff7c7_00008 | RUNNING    | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |             |                      |\n",
      "| train_model_ff7c7_00009 | PENDING    |                 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00008:\n",
      "  MAPE: 1.1997880512791606\n",
      "  date: 2022-07-14_23-26-45\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 10.461833953857422\n",
      "  time_this_iter_s: 10.461833953857422\n",
      "  time_total_s: 10.461833953857422\n",
      "  timestamp: 1657830405\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00008\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:45,845\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:49,509\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.2137604969892338\n",
      "  date: 2022-07-14_23-26-50\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 52.95839262008667\n",
      "  time_this_iter_s: 9.830996751785278\n",
      "  time_total_s: 52.95839262008667\n",
      "  timestamp: 1657830410\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:50,113\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00008:\n",
      "  MAPE: 2.5160022686616244\n",
      "  date: 2022-07-14_23-26-52\n",
      "  done: true\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 16.789366722106934\n",
      "  time_this_iter_s: 2.6633973121643066\n",
      "  time_total_s: 16.789366722106934\n",
      "  timestamp: 1657830412\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00008\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:52 (running for 00:02:07.95)\n",
      "Memory usage on this node: 7.0/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.20639391432270093 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (1 PENDING, 5 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.21376  |                    4 |\n",
      "| train_model_ff7c7_00009 | PENDING    |                 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:52,172\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "2022-07-14 23:26:52,990\tWARNING util.py:214 -- The `start_trial` operation took 0.616 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:53 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 73 samples.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:53 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:54 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:54 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:54 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:54 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:26:54 pytorch_lightning.callbacks.model_summary INFO: \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m   | Name          | Type             | Params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 0 | criterion     | MSELoss          | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 1 | train_metrics | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2 | val_metrics   | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 3 | stacks        | ModuleList       | 39.7 M\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 39.7 M    Trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 1.4 K     Non-trainable params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 39.7 M    Total params\n",
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 317.279   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:26:58 (running for 00:02:13.72)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.20639391432270093 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.21376  |                    4 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.21453208532688342\n",
      "  date: 2022-07-14_23-26-59\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 62.21383094787598\n",
      "  time_this_iter_s: 9.255438327789307\n",
      "  time_total_s: 62.21383094787598\n",
      "  timestamp: 1657830419\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:26:59,369\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:27:04 (running for 00:02:20.06)\n",
      "Memory usage on this node: 7.1/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.20639391432270093 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.214532 |                    5 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:27:07,662\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.18911377587640665\n",
      "  date: 2022-07-14_23-27-07\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 70.50560235977173\n",
      "  time_this_iter_s: 8.291771411895752\n",
      "  time_total_s: 70.50560235977173\n",
      "  timestamp: 1657830427\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:27:12 (running for 00:02:28.49)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.189114 |                    6 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.15400010641281572\n",
      "  date: 2022-07-14_23-27-15\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 78.14062762260437\n",
      "  time_this_iter_s: 7.635025262832642\n",
      "  time_total_s: 78.14062762260437\n",
      "  timestamp: 1657830435\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:27:15,296\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:27:20 (running for 00:02:35.94)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.154    |                    7 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.22170228402079473\n",
      "  date: 2022-07-14_23-27-24\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 86.9522020816803\n",
      "  time_this_iter_s: 8.811574459075928\n",
      "  time_total_s: 86.9522020816803\n",
      "  timestamp: 1657830444\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:27:24,108\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:27:29 (running for 00:02:44.81)\n",
      "Memory usage on this node: 7.3/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |             |                      |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.221702 |                    8 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:27:30,362\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00005:\n",
      "  MAPE: 1.1347805815304624\n",
      "  date: 2022-07-14_23-27-30\n",
      "  done: false\n",
      "  experiment_id: 1072f785179b447e8c199c68cfbf8d6b\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 6508\n",
      "  time_since_restore: 150.35592889785767\n",
      "  time_this_iter_s: 150.35592889785767\n",
      "  time_total_s: 150.35592889785767\n",
      "  timestamp: 1657830450\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00005\n",
      "  warmup_time: 0.024004459381103516\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:27:33,667\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.18645473309929642\n",
      "  date: 2022-07-14_23-27-33\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 96.51207947731018\n",
      "  time_this_iter_s: 9.559877395629883\n",
      "  time_total_s: 96.51207947731018\n",
      "  timestamp: 1657830453\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:27:34 (running for 00:02:50.33)\n",
      "Memory usage on this node: 7.1/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.186455 |                    9 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:27:39 (running for 00:02:55.37)\n",
      "Memory usage on this node: 7.0/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.186455 |                    9 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.15522620652130903\n",
      "  date: 2022-07-14_23-27-41\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 104.13849115371704\n",
      "  time_this_iter_s: 7.62641167640686\n",
      "  time_total_s: 104.13849115371704\n",
      "  timestamp: 1657830461\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:27:41,294\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:27:46 (running for 00:03:01.92)\n",
      "Memory usage on this node: 7.3/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.155226 |                   10 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.1416713321108131\n",
      "  date: 2022-07-14_23-27-49\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 112.23998236656189\n",
      "  time_this_iter_s: 8.101491212844849\n",
      "  time_total_s: 112.23998236656189\n",
      "  timestamp: 1657830469\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:27:49,396\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:27:55 (running for 00:03:11.11)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: None | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 6.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00007 | RUNNING    | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.141671 |                   11 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.16161834979135847\n",
      "  date: 2022-07-14_23-27-57\n",
      "  done: false\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 120.46468162536621\n",
      "  time_this_iter_s: 8.224699258804321\n",
      "  time_total_s: 120.46468162536621\n",
      "  timestamp: 1657830477\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=15192)\u001b[0m 2022-07-14 23:27:57,621\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00007:\n",
      "  MAPE: 0.16161834979135847\n",
      "  date: 2022-07-14_23-27-57\n",
      "  done: true\n",
      "  experiment_id: c5a1959184df4149808c56ce14673a92\n",
      "  experiment_tag: 7_batch_size=16,dropout=0.1643,num_blocks=3,num_stacks=64\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 15192\n",
      "  time_since_restore: 120.46468162536621\n",
      "  time_this_iter_s: 8.224699258804321\n",
      "  time_total_s: 120.46468162536621\n",
      "  timestamp: 1657830477\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: ff7c7_00007\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-07-14 23:28:03,543\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Andrew\\miniconda3\\python.exe\" C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=64841 --object-store-name=tcp://127.0.0.1:65201 --raylet-name=tcp://127.0.0.1:65376 --redis-address=None --storage=None --temp-dir=C:\\Users\\Andrew\\AppData\\Local\\Temp\\ray --metrics-agent-port=65027 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:65208 --redis-password=5241590000000000 --startup-token=10 --runtime-env-hash=694371325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:03 (running for 00:03:19.26)\n",
      "Memory usage on this node: 6.1/7.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:08 (running for 00:03:24.31)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 23:28:09,480\tWARNING util.py:214 -- The `on_step_begin` operation took 0.752 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:14 (running for 00:03:30.14)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:20 (running for 00:03:36.40)\n",
      "Memory usage on this node: 6.9/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:25 (running for 00:03:41.45)\n",
      "Memory usage on this node: 6.9/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:30 (running for 00:03:46.50)\n",
      "Memory usage on this node: 7.0/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    6.38342  |                    1 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:28:31,366\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00001:\n",
      "  MAPE: 1.127616812610806\n",
      "  date: 2022-07-14_23-28-31\n",
      "  done: false\n",
      "  experiment_id: 165379d311a540dc8317526e3cbddcc0\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12664\n",
      "  time_since_restore: 211.3260543346405\n",
      "  time_this_iter_s: 168.00366735458374\n",
      "  time_total_s: 211.3260543346405\n",
      "  timestamp: 1657830511\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: ff7c7_00001\n",
      "  warmup_time: 0.03100752830505371\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:36 (running for 00:03:52.27)\n",
      "Memory usage on this node: 7.0/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:41 (running for 00:03:57.32)\n",
      "Memory usage on this node: 7.0/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:46 (running for 00:04:02.52)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:52 (running for 00:04:07.59)\n",
      "Memory usage on this node: 7.3/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:28:57 (running for 00:04:12.88)\n",
      "Memory usage on this node: 7.3/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:02 (running for 00:04:17.92)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:07 (running for 00:04:23.40)\n",
      "Memory usage on this node: 7.3/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:12 (running for 00:04:28.47)\n",
      "Memory usage on this node: 6.9/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:18 (running for 00:04:33.74)\n",
      "Memory usage on this node: 7.0/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:23 (running for 00:04:38.77)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:28 (running for 00:04:43.93)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |        MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 1102.56     |                    1 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |    1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |    1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |             |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |             |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |    0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |    1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |    1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |    0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |    2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:29:29,091\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00000:\n",
      "  MAPE: 0.645752583914728\n",
      "  date: 2022-07-14_23-29-29\n",
      "  done: false\n",
      "  experiment_id: cef0e99354ea440aa2f5ed43bac9c53f\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 13852\n",
      "  time_since_restore: 279.8345866203308\n",
      "  time_this_iter_s: 267.9267041683197\n",
      "  time_total_s: 279.8345866203308\n",
      "  timestamp: 1657830569\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: ff7c7_00000\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:35 (running for 00:04:51.13)\n",
      "Memory usage on this node: 7.1/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.645753 |                    2 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |          |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    |          |                      |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 10.721856352718206\n",
      "  date: 2022-07-14_23-29-38\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 165.8260416984558\n",
      "  time_this_iter_s: 165.8260416984558\n",
      "  time_total_s: 165.8260416984558\n",
      "  timestamp: 1657830578\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:29:38,734\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:43 (running for 00:04:59.51)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 5.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |      MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-----------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 |  0.645753 |                    2 |\n",
      "| train_model_ff7c7_00001 | RUNNING    | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    |  1.12762  |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    |  1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |           |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 10.7219   |                    1 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    |  0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    |  1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    |  1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    |  0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    |  2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+-----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12664)\u001b[0m 2022-07-14 23:29:47,063\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00001:\n",
      "  MAPE: 1.447885605019147\n",
      "  date: 2022-07-14_23-29-47\n",
      "  done: true\n",
      "  experiment_id: 165379d311a540dc8317526e3cbddcc0\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12664\n",
      "  time_since_restore: 287.0288107395172\n",
      "  time_this_iter_s: 75.70275640487671\n",
      "  time_total_s: 287.0288107395172\n",
      "  timestamp: 1657830587\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00001\n",
      "  warmup_time: 0.03100752830505371\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-07-14 23:29:48,277\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Andrew\\miniconda3\\python.exe\" C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=64841 --object-store-name=tcp://127.0.0.1:65201 --raylet-name=tcp://127.0.0.1:65376 --redis-address=None --storage=None --temp-dir=C:\\Users\\Andrew\\AppData\\Local\\Temp\\ray --metrics-agent-port=65027 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:65208 --redis-password=5241590000000000 --startup-token=7 --runtime-env-hash=694371325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 3.2323538664565876\n",
      "  date: 2022-07-14_23-29-49\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 176.76258516311646\n",
      "  time_this_iter_s: 10.936543464660645\n",
      "  time_total_s: 176.76258516311646\n",
      "  timestamp: 1657830589\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:49 (running for 00:05:05.31)\n",
      "Memory usage on this node: 6.9/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.2495166264561481\n",
      "Resources requested: 4.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.645753 |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 1.13478  |                    1 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |          |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 3.23235  |                    2 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:29:49,700\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:29:51,555\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00005:\n",
      "  MAPE: 2.8485106724705926\n",
      "  date: 2022-07-14_23-29-51\n",
      "  done: false\n",
      "  experiment_id: 1072f785179b447e8c199c68cfbf8d6b\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 6508\n",
      "  time_since_restore: 291.54470038414\n",
      "  time_this_iter_s: 141.18877148628235\n",
      "  time_total_s: 291.54470038414\n",
      "  timestamp: 1657830591\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: ff7c7_00005\n",
      "  warmup_time: 0.024004459381103516\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:29:56 (running for 00:05:12.30)\n",
      "Memory usage on this node: 7.3/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -1.2495166264561481\n",
      "Resources requested: 4.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.645753 |                    2 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 2.84851  |                    2 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |          |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 3.23235  |                    2 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:30:00,421\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00000:\n",
      "  MAPE: 0.11994028951666064\n",
      "  date: 2022-07-14_23-30-00\n",
      "  done: false\n",
      "  experiment_id: cef0e99354ea440aa2f5ed43bac9c53f\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 13852\n",
      "  time_since_restore: 311.15453577041626\n",
      "  time_this_iter_s: 31.31994915008545\n",
      "  time_total_s: 311.15453577041626\n",
      "  timestamp: 1657830600\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00000\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n",
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 0.37623261046324474\n",
      "  date: 2022-07-14_23-30-01\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 188.22638773918152\n",
      "  time_this_iter_s: 11.463802576065063\n",
      "  time_total_s: 188.22638773918152\n",
      "  timestamp: 1657830601\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:30:01,164\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:30:06 (running for 00:05:21.79)\n",
      "Memory usage on this node: 7.2/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -0.7136901291781971\n",
      "Resources requested: 4.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00000 with MAPE=0.11994028951666064 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 64, 'dropout': 0.0008876227471853682}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.11994  |                    3 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 2.84851  |                    2 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |          |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 0.376233 |                    3 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00000:\n",
      "  MAPE: 0.12527335444261742\n",
      "  date: 2022-07-14_23-30-09\n",
      "  done: false\n",
      "  experiment_id: cef0e99354ea440aa2f5ed43bac9c53f\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 13852\n",
      "  time_since_restore: 320.3523008823395\n",
      "  time_this_iter_s: 9.197765111923218\n",
      "  time_total_s: 320.3523008823395\n",
      "  timestamp: 1657830609\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: ff7c7_00000\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:30:09,638\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 0.3975324851481165\n",
      "  date: 2022-07-14_23-30-10\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 197.91726350784302\n",
      "  time_this_iter_s: 9.690875768661499\n",
      "  time_total_s: 197.91726350784302\n",
      "  timestamp: 1657830610\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:30:10,856\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:30:15 (running for 00:05:31.50)\n",
      "Memory usage on this node: 7.1/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -0.7136901291781971\n",
      "Resources requested: 4.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00000 with MAPE=0.12527335444261742 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 64, 'dropout': 0.0008876227471853682}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.125273 |                    4 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 2.84851  |                    2 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |          |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 0.397532 |                    4 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00000:\n",
      "  MAPE: 0.3245139711653297\n",
      "  date: 2022-07-14_23-30-17\n",
      "  done: false\n",
      "  experiment_id: cef0e99354ea440aa2f5ed43bac9c53f\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 13852\n",
      "  time_since_restore: 328.6732633113861\n",
      "  time_this_iter_s: 8.32096242904663\n",
      "  time_total_s: 328.6732633113861\n",
      "  timestamp: 1657830617\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: ff7c7_00000\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:30:17,960\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 0.149697800895911\n",
      "  date: 2022-07-14_23-30-19\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 206.6353166103363\n",
      "  time_this_iter_s: 8.718053102493286\n",
      "  time_total_s: 206.6353166103363\n",
      "  timestamp: 1657830619\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:30:19,574\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:30:24 (running for 00:05:40.37)\n",
      "Memory usage on this node: 7.3/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1977538450995538 | Iter 3.000: -0.7136901291781971\n",
      "Resources requested: 4.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00000 | RUNNING    | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.324514 |                    5 |\n",
      "| train_model_ff7c7_00005 | RUNNING    | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 2.84851  |                    2 |\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    |          |                      |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 0.149698 |                    5 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:30:26,252\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00006:\n",
      "  MAPE: 2.223482388973992\n",
      "  date: 2022-07-14_23-30-26\n",
      "  done: false\n",
      "  experiment_id: 06a9d814057246ae88a3915674f13ce1\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 7176\n",
      "  time_since_restore: 270.4562313556671\n",
      "  time_this_iter_s: 270.4562313556671\n",
      "  time_total_s: 270.4562313556671\n",
      "  timestamp: 1657830626\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: ff7c7_00006\n",
      "  warmup_time: 0.022005319595336914\n",
      "  \n",
      "Result for train_model_ff7c7_00000:\n",
      "  MAPE: 0.19921054166616492\n",
      "  date: 2022-07-14_23-30-26\n",
      "  done: true\n",
      "  experiment_id: cef0e99354ea440aa2f5ed43bac9c53f\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 13852\n",
      "  time_since_restore: 337.35054063796997\n",
      "  time_this_iter_s: 8.677277326583862\n",
      "  time_total_s: 337.35054063796997\n",
      "  timestamp: 1657830626\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: ff7c7_00000\n",
      "  warmup_time: 0.005000591278076172\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=13852)\u001b[0m 2022-07-14 23:30:26,636\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-07-14 23:30:27,334\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Andrew\\miniconda3\\python.exe\" C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=64841 --object-store-name=tcp://127.0.0.1:65201 --raylet-name=tcp://127.0.0.1:65376 --redis-address=None --storage=None --temp-dir=C:\\Users\\Andrew\\AppData\\Local\\Temp\\ray --metrics-agent-port=65027 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:65208 --redis-password=5241590000000000 --startup-token=6 --runtime-env-hash=694371325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 0.1803857814513179\n",
      "  date: 2022-07-14_23-30-28\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 215.84300422668457\n",
      "  time_this_iter_s: 9.207687616348267\n",
      "  time_total_s: 215.84300422668457\n",
      "  timestamp: 1657830628\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:30:28,781\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00005:\n",
      "  MAPE: 2.071884042988701\n",
      "  date: 2022-07-14_23-30-33\n",
      "  done: true\n",
      "  experiment_id: 1072f785179b447e8c199c68cfbf8d6b\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 6508\n",
      "  time_since_restore: 333.0086600780487\n",
      "  time_this_iter_s: 41.46395969390869\n",
      "  time_total_s: 333.0086600780487\n",
      "  timestamp: 1657830633\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00005\n",
      "  warmup_time: 0.024004459381103516\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:30:33 (running for 00:05:48.69)\n",
      "Memory usage on this node: 7.3/7.4 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1941621587712858 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 2.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    | 2.22348  |                    1 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 0.180386 |                    6 |\n",
      "| train_model_ff7c7_00000 | TERMINATED | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.199211 |                    6 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00005 | TERMINATED | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 2.07188  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=6508)\u001b[0m 2022-07-14 23:30:33,037\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-07-14 23:30:34,783\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Andrew\\miniconda3\\python.exe\" C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=64841 --object-store-name=tcp://127.0.0.1:65201 --raylet-name=tcp://127.0.0.1:65376 --redis-address=None --storage=None --temp-dir=C:\\Users\\Andrew\\AppData\\Local\\Temp\\ray --metrics-agent-port=65027 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:65208 --redis-password=5241590000000000 --startup-token=11 --runtime-env-hash=694371325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 0.25395544105530193\n",
      "  date: 2022-07-14_23-30-36\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 223.49629187583923\n",
      "  time_this_iter_s: 7.653287649154663\n",
      "  time_total_s: 223.49629187583923\n",
      "  timestamp: 1657830636\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:30:36,434\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00006:\n",
      "  MAPE: 2.6019973871663127\n",
      "  date: 2022-07-14_23-30-40\n",
      "  done: false\n",
      "  experiment_id: 06a9d814057246ae88a3915674f13ce1\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 7176\n",
      "  time_since_restore: 284.8803415298462\n",
      "  time_this_iter_s: 14.424110174179077\n",
      "  time_total_s: 284.8803415298462\n",
      "  timestamp: 1657830640\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: ff7c7_00006\n",
      "  warmup_time: 0.022005319595336914\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:30:40 (running for 00:05:56.29)\n",
      "Memory usage on this node: 5.5/7.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1941621587712858 | Iter 3.000: -1.0511476478931494\n",
      "Resources requested: 2.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00006 | RUNNING    | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    | 2.602    |                    2 |\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 0.253955 |                    7 |\n",
      "| train_model_ff7c7_00000 | TERMINATED | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.199211 |                    6 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00005 | TERMINATED | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 2.07188  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:30:40,702\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 0.21778070818923692\n",
      "  date: 2022-07-14_23-30-44\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 231.06700348854065\n",
      "  time_this_iter_s: 7.570711612701416\n",
      "  time_total_s: 231.06700348854065\n",
      "  timestamp: 1657830644\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:30:44,006\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00006:\n",
      "  MAPE: 5.687555395386589\n",
      "  date: 2022-07-14_23-30-48\n",
      "  done: true\n",
      "  experiment_id: 06a9d814057246ae88a3915674f13ce1\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 7176\n",
      "  time_since_restore: 292.3560321331024\n",
      "  time_this_iter_s: 7.475690603256226\n",
      "  time_total_s: 292.3560321331024\n",
      "  timestamp: 1657830648\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: ff7c7_00006\n",
      "  warmup_time: 0.022005319595336914\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:30:48 (running for 00:06:03.78)\n",
      "Memory usage on this node: 5.6/7.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1941621587712858 | Iter 3.000: -1.2495166264561481\n",
      "Resources requested: 1.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00002 with MAPE=0.1339306734536803 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 32, 'dropout': 0.15070269808171471}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 0.217781 |                    8 |\n",
      "| train_model_ff7c7_00000 | TERMINATED | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.199211 |                    6 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00005 | TERMINATED | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 2.07188  |                    3 |\n",
      "| train_model_ff7c7_00006 | TERMINATED | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    | 5.68756  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=7176)\u001b[0m 2022-07-14 23:30:48,178\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-07-14 23:30:48,574\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Andrew\\miniconda3\\python.exe\" C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=64841 --object-store-name=tcp://127.0.0.1:65201 --raylet-name=tcp://127.0.0.1:65376 --redis-address=None --storage=None --temp-dir=C:\\Users\\Andrew\\AppData\\Local\\Temp\\ray --metrics-agent-port=65027 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:65208 --redis-password=5241590000000000 --startup-token=9 --runtime-env-hash=694371325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 0.11652122143344885\n",
      "  date: 2022-07-14_23-30-51\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 238.2201645374298\n",
      "  time_this_iter_s: 7.15316104888916\n",
      "  time_total_s: 238.2201645374298\n",
      "  timestamp: 1657830651\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:30:51,159\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-14 23:30:56 (running for 00:06:11.77)\n",
      "Memory usage on this node: 3.9/7.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1941621587712858 | Iter 3.000: -1.2495166264561481\n",
      "Resources requested: 1.0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00009 with MAPE=0.11652122143344885 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 64, 'dropout': 0.12751063056529557}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00009 | RUNNING    | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 0.116521 |                    9 |\n",
      "| train_model_ff7c7_00000 | TERMINATED | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.199211 |                    6 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00005 | TERMINATED | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 2.07188  |                    3 |\n",
      "| train_model_ff7c7_00006 | TERMINATED | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    | 5.68756  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 0.11194959696987743\n",
      "  date: 2022-07-14_23-30-57\n",
      "  done: false\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 244.87147068977356\n",
      "  time_this_iter_s: 6.65130615234375\n",
      "  time_total_s: 244.87147068977356\n",
      "  timestamp: 1657830657\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "Result for train_model_ff7c7_00009:\n",
      "  MAPE: 0.11194959696987743\n",
      "  date: 2022-07-14_23-30-57\n",
      "  done: true\n",
      "  experiment_id: 772b81b216764e16b099890548b50bae\n",
      "  experiment_tag: 9_batch_size=16,dropout=0.1275,num_blocks=3,num_stacks=64\n",
      "  hostname: DESKTOP-8SN3QU9\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 12496\n",
      "  time_since_restore: 244.87147068977356\n",
      "  time_this_iter_s: 6.65130615234375\n",
      "  time_total_s: 244.87147068977356\n",
      "  timestamp: 1657830657\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: ff7c7_00009\n",
      "  warmup_time: 0.022004127502441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-14 23:30:57 (running for 00:06:13.47)\n",
      "Memory usage on this node: 3.9/7.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 768.000: None | Iter 384.000: None | Iter 192.000: None | Iter 96.000: None | Iter 48.000: None | Iter 24.000: None | Iter 12.000: -0.16161834979135847 | Iter 6.000: -0.1941621587712858 | Iter 3.000: -1.2495166264561481\n",
      "Resources requested: 0/6 CPUs, 0/0 GPUs, 0.0/1.54 GiB heap, 0.0/0.77 GiB objects\n",
      "Current best trial: ff7c7_00009 with MAPE=0.11194959696987743 and parameters={'batch_size': 16, 'num_blocks': 3, 'num_stacks': 64, 'dropout': 0.12751063056529557}\n",
      "Result logdir: C:\\Users\\Andrew\\ray_results\\tune_darts\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "| Trial name              | status     | loc             |   batch_size |   num_blocks |   num_stacks |     dropout |     MAPE |   training_iteration |\n",
      "|-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------|\n",
      "| train_model_ff7c7_00000 | TERMINATED | 127.0.0.1:13852 |           16 |            3 |           64 | 0.000887623 | 0.199211 |                    6 |\n",
      "| train_model_ff7c7_00001 | TERMINATED | 127.0.0.1:12664 |           64 |            3 |           64 | 0.119281    | 1.44789  |                    3 |\n",
      "| train_model_ff7c7_00002 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           32 | 0.150703    | 0.133931 |                   10 |\n",
      "| train_model_ff7c7_00003 | TERMINATED | 127.0.0.1:7176  |           32 |            5 |           32 | 0.178488    | 1.05115  |                    3 |\n",
      "| train_model_ff7c7_00004 | TERMINATED | 127.0.0.1:15192 |           32 |            2 |           64 | 0.152062    | 1.97488  |                    3 |\n",
      "| train_model_ff7c7_00005 | TERMINATED | 127.0.0.1:6508  |          128 |            5 |           64 | 0.108562    | 2.07188  |                    3 |\n",
      "| train_model_ff7c7_00006 | TERMINATED | 127.0.0.1:7176  |           32 |            2 |          128 | 0.105872    | 5.68756  |                    3 |\n",
      "| train_model_ff7c7_00007 | TERMINATED | 127.0.0.1:15192 |           16 |            3 |           64 | 0.164264    | 0.161618 |                   12 |\n",
      "| train_model_ff7c7_00008 | TERMINATED | 127.0.0.1:12496 |          128 |            4 |           32 | 0.196078    | 2.516    |                    3 |\n",
      "| train_model_ff7c7_00009 | TERMINATED | 127.0.0.1:12496 |           16 |            3 |           64 | 0.127511    | 0.11195  |                   10 |\n",
      "+-------------------------+------------+-----------------+--------------+--------------+--------------+-------------+----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=12496)\u001b[0m 2022-07-14 23:30:57,810\tWARNING pytorch_lightning.py:229 -- Metric val_Loss does not exist in `trainer.callback_metrics.\n",
      "2022-07-14 23:30:58,025\tINFO tune.py:747 -- Total run time: 373.65 seconds (373.46 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-07-14 23:30:58,184\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\Users\\Andrew\\miniconda3\\python.exe\" C:\\Users\\Andrew\\miniconda3\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=64841 --object-store-name=tcp://127.0.0.1:65201 --raylet-name=tcp://127.0.0.1:65376 --redis-address=None --storage=None --temp-dir=C:\\Users\\Andrew\\AppData\\Local\\Temp\\ray --metrics-agent-port=65027 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:65208 --redis-password=5241590000000000 --startup-token=8 --runtime-env-hash=694371325\n",
      "2022-07-14 23:30:58 darts.models.forecasting.torch_forecasting_model INFO: Train dataset contains 29488 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'batch_size': 16, 'num_blocks': 3, 'num_stacks': 64, 'dropout': 0.12751063056529557}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 23:30:58 darts.models.forecasting.torch_forecasting_model INFO: Time series values are 64-bits; casting model to float64.\n",
      "2022-07-14 23:30:58 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "2022-07-14 23:30:58 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "2022-07-14 23:30:58 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "2022-07-14 23:30:58 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "2022-07-14 23:30:58 pytorch_lightning.callbacks.model_summary INFO: \n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rnn           | LSTM             | 2.8 K \n",
      "4 | fc            | Sequential       | 1.4 K \n",
      "---------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0b060034cc4b0e93119048ae5eacd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tb = src.test_bench.TestBench(\n",
    "    class_to_test=src.lstm_darts.DartsLSTMTester,\n",
    "    path_to_data=\"./data/\"\n",
    ")\n",
    "tb.run_training_and_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ea1ec-ecf4-48d8-a0e4-36993f0090af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f33c6-413b-474c-83ac-d075a1349106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521f707-06ab-443e-b9a2-808ba7e3b66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
