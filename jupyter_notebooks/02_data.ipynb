{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df56602b-a665-458b-a581-dd1faa97b5e6",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "To fetch the data we created a repository that housed a script that fetches the data.<br>\n",
    "The link to the repository can be found here : <br>\n",
    "https://github.com/sirandreww/operate_first_prometheus_data.git\n",
    "\n",
    "We have added more information about what data is being fetched and how in that repository.\n",
    "The main point being that the data we are pulling is:\n",
    "\n",
    "## How Is Data Fetched?\n",
    "\n",
    "1. Memory-usage data for each container using this Prometheus query `sum(container_memory_working_set_bytes{name!~\".*prometheus.*\", image!=\"\", container!=\"POD\", cluster=\"moc/smaug\"}) by (container, pod, namespace, node)`.\n",
    "   \n",
    "2. CPU-usage data for each container using this Prometheus query `sum(rate(container_cpu_usage_seconds_total{name!~\".*prometheus.*\", image!=\"\", container!=\"POD\", cluster=\"moc/smaug\"}[5m])) by (container, pod, namespace, node)`.\n",
    "   \n",
    "3. Memory-usage percentage data for each node using this Prometheus query `node_memory_Active_bytes/node_memory_MemTotal_bytes*100`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987bd330-747e-46c8-a800-b04f23f1700d",
   "metadata": {},
   "source": [
    "## How Is The Data Processed After Fetching?\n",
    "\n",
    "The data is then merged and turned into json files in that repository. We have created code here that takes those json files and imports them into custom datasets for our project. Let's take a look shall we!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81dee9a8-ebc4-4234-aa2c-754f1d1af255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.framework__data_set as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80d187-a834-48fd-853c-38d9019c0652",
   "metadata": {},
   "source": [
    "Getting the dataset for container memory data, for the cointainer bridge-marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c0ff1be-d124-4174-b70d-85ded164c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.get_data_set(\n",
    "    metric=\"container_mem\",\n",
    "    application_name=\"bridge-marker\",\n",
    "    path_to_data=\"./data/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19594d6d-e7da-4bdf-b30b-a093b7cfc19c",
   "metadata": {},
   "source": [
    "Now let's plot some samples in the data to get a visual on what we're looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40edf0-35cc-4481-8246-6d2e648c2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot_dataset(number_of_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7bc29e-ed42-4781-b140-4a8911f2b953",
   "metadata": {},
   "source": [
    "As you can see the data for each application is split to many time series. Each one is continous and without any \"interruptions\" in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051335ed-5715-47f2-b3d6-050270fab98e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What Applications Will We Consider?\n",
    "\n",
    "As for the applications we're going to be learning on, let's take a look at the applications with the most data for each metric.\n",
    "\n",
    "First let's take a look at node memory usage data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063ca45-c5c0-4dc1-8d07-8a292671c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = ds.get_amount_of_data_per_application(\n",
    "    metric=\"node_mem\",\n",
    "    path_to_data=\"./data/\"\n",
    ")\n",
    "print(hist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a185e-160e-4092-a912-becf3b10fd3d",
   "metadata": {},
   "source": [
    "We'll look at the following nodes:\n",
    "1. moc/smaug\n",
    "2. emea/balrog\n",
    "\n",
    "Now let's take a look at container memory usage data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d6690-c8eb-4a0b-aca1-3232d6d05278",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = ds.get_amount_of_data_per_application(\n",
    "    metric=\"container_mem\",\n",
    "    path_to_data=\"./data/\"\n",
    ")\n",
    "print(hist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491a444-20e4-45e7-b035-90e19f51ee8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "We'll look at the following applications:\n",
    "1. nmstate-handler\n",
    "2. coredns\n",
    "3. keepalived\n",
    "\n",
    "Now let's take a look at container cpu usage data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98592ea-495f-4656-9613-dc6425a08f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = ds.get_amount_of_data_per_application(\n",
    "    metric=\"container_cpu\",\n",
    "    path_to_data=\"./data/\"\n",
    ")\n",
    "print(hist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2395bf-0854-40a6-8ea8-9197ddb6c68c",
   "metadata": {},
   "source": [
    "We'll look at the following applications:\n",
    "1. kube-rbac-proxy\n",
    "2. dns\n",
    "3. collector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d4cd07-5240-4184-9bc1-c9853e0bbe4a",
   "metadata": {},
   "source": [
    "## How Is Data Pre-Processed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95a046-44e2-4d86-b01b-cb19ffdf6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.get_data_set(\n",
    "    metric=\"container_mem\",\n",
    "    application_name=\"kube-rbac-proxy\",\n",
    "    path_to_data=\"./data/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc68a0-1772-4d4b-bcd6-eac4446c6081",
   "metadata": {},
   "source": [
    "Plot the data of this data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7570a15-39a7-4416-99d5-701dc5d8fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot_dataset(number_of_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b7204b-738b-4262-9d2e-0260bbeb36c5",
   "metadata": {},
   "source": [
    "As we can see, we have a sample for each minute, we can further subsample the data to get data that is easier to generalize. Here we change the dataset so it is has samples 5 minutes appart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dfbfeb-3e99-4ee1-8aa9-4a6a8f27f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sub_sample_data(sub_sample_rate=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd160b-cd02-4f1c-aa07-c32d43931987",
   "metadata": {},
   "source": [
    "Dropping series that are shorter than 10 sample long (less than 5 * 10 minutes long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ddfe4-f6cd-4bfe-af4f-b64f13f5308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data set size before:\", len(dataset))\n",
    "dataset.filter_data_that_is_too_short(data_length_limit=10)\n",
    "print(\"Data set size after:\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb6055-fa9b-4e57-b47b-6bbd0d5a8e5a",
   "metadata": {},
   "source": [
    "Let's plot again to see how the samples look now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc21148-c9a6-4419-b397-00887afa2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot_dataset(number_of_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d0c60-6baa-4c8a-9c5c-19ccd5703079",
   "metadata": {},
   "source": [
    "The data is highly variable and is not scaled, let's scale it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049316dd-cb2b-43b2-a67b-ee46a8dd3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.scale_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff082597-2663-4759-9c03-11a9fa096f94",
   "metadata": {},
   "source": [
    "Let's plot again to see how the samples look now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef5814-b8a4-46df-b271-c3f80a9b5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot_dataset(number_of_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be142412-8c3b-4eb3-ac31-7fffc9640548",
   "metadata": {},
   "source": [
    "Now we can split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56262e1a-0dde-4a45-8fe1-08e61348c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dataset.split_to_train_and_test(test_percentage=0.2)\n",
    "print(f\"Amount of train data is {len(train)}\")\n",
    "print(f\"Amount of test data is {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9a06d-b063-4570-8a15-55c21c61149e",
   "metadata": {},
   "source": [
    "This is the preprocessing that is done to the data each time we use it for trainning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a15257-f894-471a-a931-fab50bb4ce20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
