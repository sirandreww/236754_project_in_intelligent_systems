{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df56602b-a665-458b-a581-dd1faa97b5e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "## Lessons alongst the way.\n",
    "\n",
    "1. Youtube tutorials and blogs cheat, we have yet to find an lstm implementation which does not use the true values to predict further than one sample into the future. It's so common that in fact that we felt like we might have missed something. But then we found a video that talks about just that, for more information watch this : https://www.youtube.com/watch?v=6t9hKclQNH4&ab_channel=LazyProgrammer.\n",
    "\n",
    "2. One step forcasting (forcasting one step into the future) is surprisingly effective. We started with the notion that it cannot work, since the errors would accumulate over time and would result in bad predictions. But they actually work quite well in some cases.\n",
    "\n",
    "3. It is hard to quantify how good a prediction is, some prediction look very close but end up getting a bad f1 or a bad MASE. Some look totally off but get good grades in either F1 or MASE.\n",
    "\n",
    "## Metrics\n",
    "\n",
    "1. Percision - Out of all true predictions, what percentage of which are true.\n",
    "\n",
    "2. Recall - Out of all the truely positive value, what percentage of which did you get right by identifying that they are positive.\n",
    "\n",
    "3. F1 - This metric is between one and zero, it is essentially a harmonic mean of the precision and recall. For time series forcasting positive and negative relate to if the graph is rising or falling between each two points.\n",
    "\n",
    "4. MAE - Mean Absolute Error, like MSE except absolute instead of square.\n",
    "\n",
    "5. MASE - The MAE of a prediction devided by the MAE of the naieve prediction, which is to simply predict the value of the previous sample.\n",
    "\n",
    "## Results:\n",
    "\n",
    "### DumbPredictor\n",
    "\n",
    "| metric | app | training time | mse | precision | recall | F1 | MASE | MAPE |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| node_mem | moc/smaug | 0 seconds   | 0.01141 | 0.70443 | 0.74181 | 0.71829  | 61.60006 | 22.01294 |\n",
    "| node_mem | emea/balrog | 0 seconds   | 0.00292 | 0.67102 | 0.68123 | 0.66829  | 8.864 | 4.96183 |\n",
    "| container_mem | nmstate-handler | 0 seconds   | 1.72279 | 0.47696 | 0.49838 | 0.48092  | 1.1072 | 642.99626 |\n",
    "| container_mem | coredns | 0 seconds   | 0.04026 | 0.47257 | 0.49789 | 0.47835  | 1.44932 | 96.40467 |\n",
    "| container_mem | keepalived | 0 seconds   | 0.01764 | 0.5267 | 0.55364 | 0.53366  | 1.85824 | 43.92158 |\n",
    "| container_cpu | kube-rbac-proxy | 0 seconds   | 0.13267 | 0.47127 | 0.50116 | 0.47905  | 1.18257 | 129.85771 |\n",
    "| container_cpu | dns | 0 seconds   | 0.1814 | 0.47372 | 0.5048 | 0.48237  | 1.22762 | 203.75586 |\n",
    "| container_cpu | collector | 0 seconds   | 0.53843 | 0.48234 | 0.51593 | 0.49214  | 1.93528 | 189.54327 |\n",
    "\n",
    "### LSTM Pytorch\n",
    "\n",
    "### LSTM Darts\n",
    "\n",
    "### TCN\n",
    "\n",
    "### DeepAR\n",
    "\n",
    "### Transformer\n",
    "\n",
    "### N-BEATS\n",
    "\n",
    "## Best Models in terms of F1\n",
    "\n",
    "1. For "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec7c2c-e3f7-4a01-8a53-e1b62d64dd55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
