{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df56602b-a665-458b-a581-dd1faa97b5e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Long Short-Term Memory (LSTM)\n",
    "\n",
    "## What is LSTM? \n",
    "LSTM stands for long short-term memory networks, used in the field of Deep Learning. It is a variety of recurrent neural networks (RNNs) that are capable of learning long-term dependencies, especially in sequence prediction problems. \n",
    "LSTM has feedback connections, i.e., it is capable of processing the entire sequence of data, apart from single data points such as images.\n",
    "This finds application in speech recognition, machine translation, etc. LSTM is a special kind of RNN, which shows outstanding performance on a large variety of problems.\n",
    "\n",
    "worth watching: https://www.youtube.com/watch?v=b61DPVFX03I&t=329s\n",
    "\n",
    "## Our LSTM Implementation:\n",
    "\n",
    "Our implementation of the LSTM is available in `./src/lstm.py`. The implementation includes the model as well as all that's needed for the test besnch to be able to use the model. let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a692a2a-ce27-4151-9094-d25ecee04bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.lstm as lstm\n",
    "import src.test_bench as bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17ea1ec-ecf4-48d8-a0e4-36993f0090af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST BENCH] Powering on test bench\n",
      "[TEST BENCH] testing metric='node_mem', app='moc/smaug'.\n",
      "[TEST BENCH] Fetching data for metric='node_mem', app='moc/smaug'.\n",
      "[TEST BENCH] Subsampling data from 1 sample per 1 minute to 1 sample per 5 minutes.\n",
      "[TEST BENCH] Throwing out data that is less than 100 minutes long.\n",
      "[TEST BENCH] Scaling data.\n",
      "[TEST BENCH] Splitting data into train and test\n",
      "[TEST BENCH] Amount of train data is 768\n",
      "[TEST BENCH] Amount of test data is 191\n",
      "[TEST BENCH] Making an instance of the class we want to test\n",
      "[LSTM] padding = -10\n",
      "[LSTM] batch_size = 128\n",
      "[LSTM] num_epochs = 100\n",
      "[LSTM] learning_rate = 0.01\n",
      "[LSTM] criterion = MSELoss()\n",
      "[TEST BENCH] Starting training loop\n",
      "[LSTM] model = LSTMPredictor(\n",
      "  (model): Sequential(\n",
      "    (0): LSTM(1, 128, num_layers=7, batch_first=True, dropout=0.1)\n",
      "    (1): ExtractTensorAfterLSTM()\n",
      "    (2): Linear(in_features=128, out_features=495, bias=True)\n",
      "  )\n",
      ")\n",
      "[LSTM] optimizer = Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "[LSTM] Length of list_of_samples =  27648\n",
      "[LSTM] Epoch 1 / 100. Last epoch time was 0\n",
      "[LSTM] loss of batch 1 / 216: 0.9561688899993896\n",
      "[LSTM] loss of batch 2 / 216: 0.9070619940757751\n",
      "[LSTM] loss of batch 3 / 216: 1.3393337726593018\n",
      "[LSTM] loss of batch 4 / 216: 1.4579404592514038\n",
      "[LSTM] loss of batch 5 / 216: 0.5237762928009033\n",
      "[LSTM] loss of batch 6 / 216: 0.9346663355827332\n",
      "[LSTM] loss of batch 7 / 216: 0.8789713978767395\n",
      "[LSTM] loss of batch 8 / 216: 0.6805556416511536\n",
      "[LSTM] loss of batch 9 / 216: 1.5208241939544678\n",
      "[LSTM] loss of batch 10 / 216: 0.7183664441108704\n",
      "[LSTM] loss of batch 11 / 216: 0.9865451455116272\n",
      "[LSTM] loss of batch 12 / 216: 0.7335957884788513\n",
      "[LSTM] loss of batch 13 / 216: 0.8822125196456909\n",
      "[LSTM] loss of batch 14 / 216: 0.8244772553443909\n",
      "[LSTM] loss of batch 15 / 216: 0.4999569058418274\n",
      "[LSTM] loss of batch 16 / 216: 0.699292778968811\n",
      "[LSTM] loss of batch 17 / 216: 0.8572838306427002\n",
      "[LSTM] loss of batch 18 / 216: 1.0643424987792969\n",
      "[LSTM] loss of batch 19 / 216: 1.1756105422973633\n",
      "[LSTM] loss of batch 20 / 216: 1.0834468603134155\n",
      "[LSTM] loss of batch 21 / 216: 0.7022987604141235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4b8933e28c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpath_to_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./data/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training_and_tests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\uni\\B.A\\semester 10\\236754 - Project in Intelligent Systems\\git_repo\\236754_project_in_intelligent_systems\\jupyter_notebooks\\src\\test_bench.py\u001b[0m in \u001b[0;36mrun_training_and_tests\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m             \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"metric\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"testing metric='{metric}', app='{app}'.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__do_one_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m             \u001b[0mfull_report\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_report\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__tests_to_perform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\uni\\B.A\\semester 10\\236754 - Project in Intelligent Systems\\git_repo\\236754_project_in_intelligent_systems\\jupyter_notebooks\\src\\test_bench.py\u001b[0m in \u001b[0;36m__do_one_test\u001b[1;34m(self, dictionary)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Starting training loop\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mtraining_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn_from_data_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[0mtraining_stop_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"Training took {training_stop_time - training_start_time} seconds.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\uni\\B.A\\semester 10\\236754 - Project in Intelligent Systems\\git_repo\\236754_project_in_intelligent_systems\\jupyter_notebooks\\src\\lstm.py\u001b[0m in \u001b[0;36mlearn_from_data_set\u001b[1;34m(self, training_data_set)\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__do_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_data_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_as_df_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow_much_to_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\uni\\B.A\\semester 10\\236754 - Project in Intelligent Systems\\git_repo\\236754_project_in_intelligent_systems\\jupyter_notebooks\\src\\lstm.py\u001b[0m in \u001b[0;36m__do_training\u001b[1;34m(self, training_data_set)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"Epoch {e + 1} / {self.num_epochs}. Last epoch time was {epoch_time}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             sum_of_losses = self.__do_epoch(\n\u001b[0m\u001b[0;32m    259\u001b[0m                 \u001b[0mepoch_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[0mlist_of_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist_of_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\uni\\B.A\\semester 10\\236754 - Project in Intelligent Systems\\git_repo\\236754_project_in_intelligent_systems\\jupyter_notebooks\\src\\lstm.py\u001b[0m in \u001b[0;36m__do_epoch\u001b[1;34m(self, epoch_num, list_of_batch, training_data_set)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0msum_of_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__do_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"loss of batch {i + 1} / {len(list_of_batch)}: {loss}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0msum_of_losses\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\uni\\B.A\\semester 10\\236754 - Project in Intelligent Systems\\git_repo\\236754_project_in_intelligent_systems\\jupyter_notebooks\\src\\lstm.py\u001b[0m in \u001b[0;36m__do_batch\u001b[1;34m(self, batch_data)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mloss_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrue_if_pad\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfalse_if_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tb = bench.TestBench(\n",
    "    class_to_test=lstm.LSTMTester,\n",
    "#     tests_to_perform=[\n",
    "#         {\"metric\": \"node_mem\", \"app\": \"moc/smaug\", \"test percentage\": 0.2, \"sub sample rate\": 5,\n",
    "#          \"data length limit\": 20},\n",
    "#     ],\n",
    "    path_to_data=\"./data/\"\n",
    ")\n",
    "tb.run_training_and_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f33c6-413b-474c-83ac-d075a1349106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521f707-06ab-443e-b9a2-808ba7e3b66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
